{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN-2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srinivasiyengar/srinivas/blob/master/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XStNTNdDksR2"
      },
      "source": [
        "                                                       REFERENCE\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Itt1ijB4Akda"
      },
      "source": [
        "\n",
        "                                \n",
        "*   https://www.edureka.co/blog/k-nearest-neighbors-algorithm/\n",
        "*   https://github.com/sagarmk/Knn-from-scratch/blob/master/knn.py\n",
        "*   https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/\n",
        "*   http://www.data-machine.net/nmtutorial/distanceweightedknnalgorithm.htm\n",
        "*   https://www.geeksforgeeks.org/implementation-k-nearest-neighbors/\n",
        "*   https://dataaspirant.com/k-nearest-neighbor-algorithm-implementaion-python-scratch/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3IBf7AllOEY"
      },
      "source": [
        "                                                  K-NEAREST NEIGHBOURS\n",
        "\n",
        "\n",
        "*   K-nearest neighbors (KNN) is a **supervised ML algorithm** which can be used for both classification as well as regression predictive problems\n",
        "*   It is a **lazy learning algorithm** because it uses all the data for training while classification.\n",
        "*   It is a **non-parametric learning algorithm** because it doesn’t assume anything about the underlying data.\n",
        "*   Since the KNN algorithm requires no training before making predictions, **new data can be added seamlessly** which will not impact the accuracy of the algorithm.\n",
        "*   it **needs feature scaling** to get accurate predictions. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWLjPMAD3auH"
      },
      "source": [
        "                                                IMPORTING THE LIBRARIES:\n",
        "\n",
        "*   **Pandas** is a famous library that provides various data structures and operations for manipulating numerical data and time series. \n",
        "*   **NumPy** is one of the most powerful Python libraries. It is used in the industry for array computing\n",
        "* **randrange** is a function used to call out any random number between the start and stop which are the input features of the function.\n",
        "*   **Math** Library provides us access to some common math functions and constants in Python\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "notQxRcKuLJK"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import randrange\n",
        "import math\n",
        "from math import sqrt\n",
        "import operator "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9CydyuU5AAp"
      },
      "source": [
        "                                                   EUCLIDEAN DISTANCE\n",
        "**euclidean_distance** function takes in input 2 rows and  calculates the absolute diffrence between the elements(column values) of 2 rows by iterating through each column.                      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCLriZGuxHaL"
      },
      "source": [
        "#https://www.edureka.co/blog/k-nearest-neighbors-algorithm/\n",
        "\n",
        "def euclidean_distance(row1, row2):\n",
        "  distance = 0.0\n",
        "  for i in range(len(row1)-1):\n",
        "    distance += pow((row1[i] - row2[i]), 2)  \n",
        "  return math.sqrt(distance)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAK3pP3C7xXC"
      },
      "source": [
        "                                                   NEIGHBOURS\n",
        "the **get_neighbors** function helps us to find the best neighbours set for a given row from the whole training data.\n",
        "\n",
        "WORKING:\n",
        "\n",
        "*   the function takes in as input the training set,test row for which we want to find closest neighbours and the number of closest neighbours we want to return as output(k).\n",
        "*   we iterate through each row of the training data and calculate the distance of each row with our test row and append it to a list(distances) simultanously.\n",
        "*   then we sort the distances in ascending order such that index 0 of distances refers to the closest row to the test row.\n",
        "\n",
        "*   we append the top k rows of the distances to neighbours list and their corresponding distances in the dist1 list \n",
        "*   neighbours and dist1 are returned\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOmu3Be4waQg"
      },
      "source": [
        "#https://dataaspirant.com/k-nearest-neighbor-algorithm-implementaion-python-scratch/\n",
        "def get_neighbors(trainingSet, testInstance, k):\n",
        "    distances = []\n",
        "    for x in range(len(trainingSet)):\n",
        "        dist = euclidean_distance(testInstance, trainingSet[x])\n",
        "        distances.append((trainingSet[x], dist))\n",
        "    distances.sort(key=operator.itemgetter(1))\n",
        "    neighbors = []\n",
        "    dist1 = []\n",
        "    for x in range(k):\n",
        "        neighbors.append(distances[x][0])\n",
        "        dist1.append(distances[x][1])\n",
        "    return (neighbors, dist1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJZPOzC4FJT5"
      },
      "source": [
        "                                                    PREDICTION\n",
        "\n",
        " the **predict_classification** function decides the output of the test row from the output values of the closest neighbours.\n",
        "\n",
        "WORKING:\n",
        "*   the function takes in as input the training set,test row for which we want to find closest neighbours and the number of closest neighbours we want to return as output(k).\n",
        "\n",
        "*   we get the best neighbours using the get_neighbours defined earlier.\n",
        "\n",
        "\n",
        "\n",
        "*   we iterate through each neighbour and find out their **weighted response** which is the their **output value multiplied by their inverse distance** which signifies the importance of each neighbour.\n",
        "\n",
        "*   we add the sum of the weighted response and the total weights in  variables.\n",
        "*   sum of weighted response  divided by the total weight gives the output.\n",
        "\n",
        "*   if the output greater than 0.5 then we set prediction to be 1 else 0.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovDULqCqT8ws"
      },
      "source": [
        "def predict_classification(train, test_row, num_neighbors):\n",
        "  neighbors = get_neighbors(train, test_row, num_neighbors)\n",
        "  class_Votes = 0\n",
        "  total_weight = 0\n",
        "  neighbours_rows = list(neighbors[0])\n",
        "  dist_dict = list(neighbors[1])\n",
        "  for x in range(len(neighbours_rows)):\n",
        "     response = neighbours_rows[x][-1]\n",
        "     weight = 1/(dist_dict[x])\n",
        "     weighted_response = response*weight\n",
        "     class_Votes += weighted_response\n",
        "     total_weight += weight\n",
        "  output = class_Votes/total_weight\n",
        "  if output > 0.5:\n",
        "     return 1\n",
        "  else:\n",
        "     return 0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmSCRnQOPnnn"
      },
      "source": [
        "the **k_nearest_neighbors** function gives out the prediction of each row of the test set using **prediction_classification** by iterating through each row of test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zir9w3BNxNHL"
      },
      "source": [
        "def k_nearest_neighbors(train, test, num_neighbors):\n",
        "\tpredictions = list()\n",
        "\tfor row in test:\n",
        "\t\toutput = predict_classification(train, row, num_neighbors)\n",
        "\t\tpredictions.append(output)\n",
        "\treturn(predictions)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oqP3D_6P-Wl"
      },
      "source": [
        "                                                      PERFORMANCE\n",
        "we calculate the performance of our algoritm by using the **F1 score** \n",
        "\n",
        "WORKING:\n",
        "\n",
        "*   we calculate the total **true positives**(TP),**false positives**(FP),**true negatives**(TN) and **false negatives**(FN) by setting conditions as shown.\n",
        "*   **precisiion** is calculated defined as **true positives/(false positives + true positives)**\n",
        "*   **recall** is calculate using defined by **true positives/(false negatives + true positives)**\n",
        "*   The **F1 score** is defined as recall **(precision*recall)/(recall + precision)**\n",
        "\n",
        "F1 score value lies between 0 and 1 with a **max value** of **1** when the predictions are exactly matching with the given data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjy3lXItBA3o"
      },
      "source": [
        "#https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
        "def perf_measure(y_actual, y_hat):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    for i in range(len(y_actual)): \n",
        "       if y_actual[i] == y_hat[i] == 1:\n",
        "           TP += 1\n",
        "       if y_hat[i] ==1 and y_actual[i] != y_hat[i]:\n",
        "           FP += 1\n",
        "       if y_actual[i] == y_hat[i] == 0:\n",
        "           TN += 1\n",
        "       if y_hat[i] == 0 and y_actual[i] != y_hat[i]:\n",
        "           FN += 1\n",
        "    precision = TP/(TP +FP)\n",
        "    recall = TP/(TP + FN)\n",
        "    F1_score = 2*precision*recall/(precision + recall)\n",
        "    return F1_score\n",
        "\t"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB5A2dhwTwaI"
      },
      "source": [
        "the **algorithm_evaluation** function takes in as input :the dataset ,the algorithm to be applied on the dataset,and the arguments of the algorithm, and gives the performance using the previously created functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dPrPEJK_8-Y"
      },
      "source": [
        "#https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
        "def algorithm_evaluation(dset, algorithm, n_folds, *args):\n",
        "  dset_split = list()\n",
        "  dset_copy = list(dset)\n",
        "  fold_size = int(len(dset) / n_folds)\n",
        "  test_set = list()\n",
        "  while len(test_set) < fold_size:\n",
        "\t\t\tindex = randrange(len(dset_copy))\n",
        "\t\t\ttest_set.append(dset_copy.pop(index))\n",
        "  train_set = list(dset_copy)\n",
        "  predicted = algorithm(train_set, test_set, *args)\n",
        "  actual = [row[-1] for row in test_set]\n",
        "  F1_score = perf_measure(actual, predicted)\n",
        "  return F1_score"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTebvkw42b7N"
      },
      "source": [
        "                                                   LOAD THE DATASET  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8jIT_S0dM6Z",
        "outputId": "13ed932d-5793-41b2-ea70-fba8b181f3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "pip install wget"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=b653570b56a5941491601d7b7b59d3ef85d0202af351fee592c7664ba655542f\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOxs-GPjyPTp",
        "outputId": "4cbc74fd-8ca6-44f9-e1ba-8894d529b42c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "!wget https://github.com/srinivasiyengar/srinivas/raw/master/breast_cancer.csv\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-22 12:17:04--  https://github.com/srinivasiyengar/srinivas/raw/master/breast_cancer.csv\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/srinivasiyengar/srinivas/master/breast_cancer.csv [following]\n",
            "--2020-10-22 12:17:05--  https://raw.githubusercontent.com/srinivasiyengar/srinivas/master/breast_cancer.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120924 (118K) [text/plain]\n",
            "Saving to: ‘breast_cancer.csv’\n",
            "\n",
            "breast_cancer.csv   100%[===================>] 118.09K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-10-22 12:17:05 (3.01 MB/s) - ‘breast_cancer.csv’ saved [120924/120924]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XslTIsN79Hvr"
      },
      "source": [
        "dset = pd.read_csv('breast_cancer.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUgF8l0Y2Ryv"
      },
      "source": [
        "                                                    ABOUT THE DATASET\n",
        "\n",
        "\n",
        "*   Features of our dataset are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.They describe characteristics of the cell nuclei present in the image\n",
        "*   Our task is to Classify the cancer stage of a patient(**malignant** or **benign**) from various features in the dataset using our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOSMCpRXkNi"
      },
      "source": [
        "                                                     NORMALIZATION\n",
        " Z-SCORE is defined by the formula:  \n",
        "> z = (x–μ)/σ ,   \n",
        " where **x** is the **observed value**, **μ** is **mean** and **σ** is the **standard deviation**\n",
        "\n",
        "WORKING:\n",
        "\n",
        "\n",
        "*   we iterate through every column and find the respective mean and standard deviations of every column.\n",
        "*   then we iterate through each row to find the find the z score and replace it to the existing value for every element in the dataset.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBCCMm49AWHg"
      },
      "source": [
        "def zscore(data):\n",
        "    (rows, cols) = data.shape\n",
        "    media = np.zeros(shape=(cols), dtype=np.float32)\n",
        "    sigma = np.zeros(shape=(cols), dtype=np.float32)\n",
        "    for j in range(cols-1):\n",
        "        media[j] = data.iloc[:,j].sum(axis=0)/rows\n",
        "        sigma[j] = data.iloc[:,j].std(axis = 0)\n",
        "    result = np.copy(data)\n",
        "    for i in range(rows):\n",
        "        for j in range(cols-1):\n",
        "            result[i,j] = ((data.iloc[i,j] - media[j]) / sigma[j])\n",
        "    return "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLqOBE-3rbDn"
      },
      "source": [
        "zscore(dset)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu2nKHjocm--"
      },
      "source": [
        "converting our dataset to list "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmUv8R3ixTvy"
      },
      "source": [
        "dset = dset.values.tolist()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5IHoqxibriE"
      },
      "source": [
        "the **str_column_to_int** function preprocesses our dataset by encoding the last or the prediction column to integers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmM7Gc_BAnQp"
      },
      "source": [
        "#https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7vqX8CBB_pA",
        "outputId": "874f2d88-0464-4800-9e31-cf605947bb6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "str_column_to_int(dset, len(dset[0])-1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B': 1, 'M': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZLswZXWcud9"
      },
      "source": [
        "                                                  TESTING ON DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A51usGdCxamu"
      },
      "source": [
        "n_folds = 5\n",
        "num_neighbors = 5"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPOUM-Stxo1H"
      },
      "source": [
        "score = algorithm_evaluation(dset, k_nearest_neighbors, n_folds, num_neighbors)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBESafNmqOTn",
        "outputId": "740fdee5-c178-42f4-9dfe-9e54f8aa788f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.974025974025974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtsYCBbt3giu"
      },
      "source": [
        "\n",
        "                                                     CONCLUSION\n",
        "\n",
        "\n",
        "*   Applied KNN algorithm on the dataset to establish a relation between the parameters to predict whether the cancer is malignant or benign.\n",
        "*   Algorithms predictions are in well accordance with the given data with an **F1 score** of **0.95**.\n",
        "\n"
      ]
    }
  ]
}